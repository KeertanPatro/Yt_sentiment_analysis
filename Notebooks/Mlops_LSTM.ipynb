{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m2DtXlZzoDIh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' 火箭o辛基 这种帖子就好比，中国gdp增长从7 降为5 ，还是在高速增长，只是没这么变态罢了，中国低端制造业难过，只不过是中国的产业在逐渐转型而已，瞧把阿三激动的，多了点密集的制造业，乐的跟吃了蜜蜂屎一样。。。\\n'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df=pd.read_csv(\"/Users/keertan.patro/Desktop/Practice/Yt_sentiment_analysis/Data/Clean/test_clean.csv\")\n",
        "text=df.iloc[424]['clean_comment']\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
            "/var/folders/hj/pb36nbg93kz0c0dn51ck371w0000gq/T/ipykernel_30158/2741804648.py:3: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  non_ascii_pattern=\"[^A-Za-z0-9\\s!?.,]\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_comment</th>\n",
              "      <th>category</th>\n",
              "      <th>new_clean_comment</th>\n",
              "      <th>processed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>happy have you what’ one great thing that’ ha...</td>\n",
              "      <td>1</td>\n",
              "      <td>happy have you what one great thing that happe...</td>\n",
              "      <td>happy one great thing happened recently</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>was museum today which described this “religi...</td>\n",
              "      <td>2</td>\n",
              "      <td>was museum today which described this religion...</td>\n",
              "      <td>museum today described religion set discrete r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>there are people who trust pakistan which has...</td>\n",
              "      <td>1</td>\n",
              "      <td>there are people who trust pakistan which has ...</td>\n",
              "      <td>people trust pakistan denied existence terrori...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>unless she gets complete congress vote jds wil...</td>\n",
              "      <td>1</td>\n",
              "      <td>unless she gets complete congress vote jds wil...</td>\n",
              "      <td>unless get complete congress vote jds win easi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>great effort hard believe odin doesn’ know abo...</td>\n",
              "      <td>1</td>\n",
              "      <td>great effort hard believe odin doesn know abou...</td>\n",
              "      <td>great effort hard believe odin know kratos rav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6791</th>\n",
              "      <td>meanwhile pakistan jpg “khan tea stall tea go...</td>\n",
              "      <td>1</td>\n",
              "      <td>meanwhile pakistan jpg khan tea stall tea good...</td>\n",
              "      <td>meanwhile pakistan jpg khan tea stall tea good...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6798</th>\n",
              "      <td>ppr team witten @ nyg\\nmcdonald @ still avail...</td>\n",
              "      <td>1</td>\n",
              "      <td>ppr team witten  nyg mcdonald  still available...</td>\n",
              "      <td>ppr team witten nyg mcdonald still available w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6803</th>\n",
              "      <td>ppr walford @ saints zach miller @ texans</td>\n",
              "      <td>0</td>\n",
              "      <td>ppr walford  saints zach miller  texans</td>\n",
              "      <td>ppr walford saint zach miller texan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6821</th>\n",
              "      <td>hahaha top tier bakchodi from modi \\ \\</td>\n",
              "      <td>1</td>\n",
              "      <td>hahaha top tier bakchodi from modi</td>\n",
              "      <td>hahaha top tier bakchodi modi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6866</th>\n",
              "      <td>how suddenly the stock market forex started go...</td>\n",
              "      <td>1</td>\n",
              "      <td>how suddenly the stock market forex started go...</td>\n",
              "      <td>suddenly stock market forex started going say ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>370 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          clean_comment  category  \\\n",
              "2      happy have you what’ one great thing that’ ha...         1   \n",
              "23     was museum today which described this “religi...         2   \n",
              "31     there are people who trust pakistan which has...         1   \n",
              "43    unless she gets complete congress vote jds wil...         1   \n",
              "76    great effort hard believe odin doesn’ know abo...         1   \n",
              "...                                                 ...       ...   \n",
              "6791   meanwhile pakistan jpg “khan tea stall tea go...         1   \n",
              "6798   ppr team witten @ nyg\\nmcdonald @ still avail...         1   \n",
              "6803         ppr walford @ saints zach miller @ texans          0   \n",
              "6821             hahaha top tier bakchodi from modi \\ \\         1   \n",
              "6866  how suddenly the stock market forex started go...         1   \n",
              "\n",
              "                                      new_clean_comment  \\\n",
              "2     happy have you what one great thing that happe...   \n",
              "23    was museum today which described this religion...   \n",
              "31    there are people who trust pakistan which has ...   \n",
              "43    unless she gets complete congress vote jds wil...   \n",
              "76    great effort hard believe odin doesn know abou...   \n",
              "...                                                 ...   \n",
              "6791  meanwhile pakistan jpg khan tea stall tea good...   \n",
              "6798  ppr team witten  nyg mcdonald  still available...   \n",
              "6803            ppr walford  saints zach miller  texans   \n",
              "6821                 hahaha top tier bakchodi from modi   \n",
              "6866  how suddenly the stock market forex started go...   \n",
              "\n",
              "                                         processed_text  \n",
              "2               happy one great thing happened recently  \n",
              "23    museum today described religion set discrete r...  \n",
              "31    people trust pakistan denied existence terrori...  \n",
              "43    unless get complete congress vote jds win easi...  \n",
              "76    great effort hard believe odin know kratos rav...  \n",
              "...                                                 ...  \n",
              "6791  meanwhile pakistan jpg khan tea stall tea good...  \n",
              "6798  ppr team witten nyg mcdonald still available w...  \n",
              "6803                ppr walford saint zach miller texan  \n",
              "6821                      hahaha top tier bakchodi modi  \n",
              "6866  suddenly stock market forex started going say ...  \n",
              "\n",
              "[370 rows x 4 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "def non_ascii_matches(text):\n",
        "    non_ascii_pattern=\"[^A-Za-z0-9\\s!?.,]\"\n",
        "    if pd.isna(text):\n",
        "        return False\n",
        "    non_ascii_matches=re.findall(non_ascii_pattern,text)\n",
        "    if non_ascii_matches:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "df[df['clean_comment'].apply(non_ascii_matches)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text=df.iloc[424]['clean_comment']\n",
        "non_ascii_matches(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2CfLIsiMK-6",
        "outputId": "56b8ae2f-4825-49dc-a1c8-79f772986194"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:3: SyntaxWarning: invalid escape sequence '\\]'\n",
            "<>:3: SyntaxWarning: invalid escape sequence '\\]'\n",
            "/var/folders/hj/pb36nbg93kz0c0dn51ck371w0000gq/T/ipykernel_30158/10035072.py:3: SyntaxWarning: invalid escape sequence '\\]'\n",
            "  url_pattern=\"https?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F\\][0-9a-fA-F]))+\"\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "def pre_process(text):\n",
        "  url_pattern=\"https?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F\\][0-9a-fA-F]))+\"\n",
        "  non_ascii_pattern=\"[^\\x00-\\x7F]+\"\n",
        "  url_matches=re.findall(url_pattern,text)\n",
        "  non_ascii_matches=re.findall(non_ascii_pattern,text)\n",
        "  if non_ascii_matches:\n",
        "    return \n",
        "  text=text.lower()\n",
        "  text=text.replace(\"\\n\",\" \")\n",
        "  text=text.strip()\n",
        "  if url_matches:\n",
        "    for url in url_matches:\n",
        "      text=text.replace(url,\"\")\n",
        "  if non_ascii_matches:\n",
        "    for non_ascii in non_ascii_matches:\n",
        "      text=text.replace(non_ascii,\"\")\n",
        "  text=text.strip()\n",
        "  if len(text.split())<=2:\n",
        "    return np.nan\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrAv6abTMO7c",
        "outputId": "3589182c-f7c5-42f7-e874-34809ba748d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/keertan.patro/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/keertan.patro/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemm=WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8dFFssxYoJc5"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"https://raw.githubusercontent.com/Himanshu-1703/reddit-sentiment-analysis/refs/heads/main/data/reddit.csv\")\n",
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_comment</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>family mormon have never tried explain them t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>buddhism has very much lot compatible with chr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>seriously don say thing first all they won get...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what you have learned yours and only yours wha...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>for your own benefit you may want read living ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       clean_comment  category\n",
              "0   family mormon have never tried explain them t...         1\n",
              "1  buddhism has very much lot compatible with chr...         1\n",
              "2  seriously don say thing first all they won get...        -1\n",
              "3  what you have learned yours and only yours wha...         0\n",
              "4  for your own benefit you may want read living ...         1"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ELiwFw7pRxLC"
      },
      "outputs": [],
      "source": [
        "stopwords=[word for word in stopwords.words('english') if word not in ('not','but','however','no','yet')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sJwZwE14RoWP"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(text):\n",
        "  new_text=\"\"\n",
        "  for word in text.split():\n",
        "    if word not in stopwords:\n",
        "      word=lemm.lemmatize(word)\n",
        "      new_text+=word+\" \"\n",
        "  return new_text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qi4xKaeToX0b"
      },
      "outputs": [],
      "source": [
        "df['new_clean_comment']=df['clean_comment'].apply(pre_process)\n",
        "df.dropna(inplace=True)\n",
        "df['processed_comment']=df['new_clean_comment'].apply(remove_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vc9HXmvAOQUL"
      },
      "outputs": [],
      "source": [
        "def get_max_length(df):\n",
        "  max_length=-float('inf')\n",
        "  top_index=0\n",
        "  for index, text in enumerate(df['processed_comment']):\n",
        "    text_len=len(text.split())\n",
        "    if text_len>max_length:\n",
        "      max_length=text_len\n",
        "      top_index=index\n",
        "  return max_length,top_index\n",
        "max_length,top_index=get_max_length(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ucr7hIsc0OeE",
        "outputId": "3852886d-8a84-4d78-ba0d-f7da382eefce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(893, 21036)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_length,top_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Rm881Vp5z8Dm"
      },
      "outputs": [],
      "source": [
        "df['new_category']=df['category'].apply(lambda x: x if x in (1,0) else 2 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "wIUQjuXV0gSn",
        "outputId": "eb89dff0-d606-4bcc-8522-d7fe8440e5c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "new_category\n",
              "1    14560\n",
              "0    10522\n",
              "2     7646\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['new_category'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_length=600"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "def get_root_directory():\n",
        "   try:\n",
        "      path=os.path.dirname(os.path.abspath(__file__))\n",
        "      prev_path=os.path.abspath(os.path.join(path,\"../../\"))\n",
        "      return prev_path\n",
        "   except Exception as e:\n",
        "      raise\n",
        "dir_path=get_root_directory()\n",
        "train_data_path=dir_path+\"/Data/Clean/train_clean.csv\"\n",
        "test_data_path=dir_path+\"/Data/Clean/test_clean.csv\"\n",
        "model_path=dir_path+\"/lstm_model.pth\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'a': 21}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "json.dump({'a':21},open(\"test.json\",'w'))\n",
        "json.load(open(\"test.json\",'r'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "4bXyFh38oiOZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import dataset,DataLoader,TensorDataset\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "b5bkln6J7QYI"
      },
      "outputs": [],
      "source": [
        "tokenizer=Tokenizer(num_words=2000,lower=True)\n",
        "tokenizer.fit_on_texts(df['processed_comment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "xApPiGbe8G9C"
      },
      "outputs": [],
      "source": [
        "vocab=tokenizer.word_index\n",
        "len(vocab)\n",
        "max_len=900\n",
        "X=tokenizer.texts_to_sequences(df['processed_comment'])\n",
        "X=pad_sequences(X,maxlen=max_len)\n",
        "y=np.array(df['new_category'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "900"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X[21036])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "rnMCu9-K_VxQ"
      },
      "outputs": [],
      "source": [
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "3gUDblNx8f5T"
      },
      "outputs": [],
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42,shuffle=True,stratify=y)\n",
        "X_train=torch.tensor(X_train,dtype=torch.long).to(device)\n",
        "X_test=torch.tensor(X_test,dtype=torch.long).to(device)\n",
        "y_train=torch.tensor(y_train,dtype=torch.long).to(device)\n",
        "y_test=torch.tensor(y_test,dtype=torch.long).to(device)\n",
        "train_dataset=TensorDataset(X_train,y_train)\n",
        "test_dataset=TensorDataset(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "j6LQmaO8tLe_"
      },
      "outputs": [],
      "source": [
        "batch_size=4\n",
        "output_dim=3\n",
        "train_dataloader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "test_dataloader=DataLoader(test_dataset,batch_size=batch_size,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "7ZoUCTi8t57w"
      },
      "outputs": [],
      "source": [
        "class Lstm_model(nn.Module):\n",
        "  def __init__(self,vocab_size,embedding_dim,hidden_dim):\n",
        "    super().__init__()\n",
        "    self.embedding=nn.Embedding(vocab_size,embedding_dim)\n",
        "    self.lstm=nn.LSTM(embedding_dim,hidden_dim,batch_first=True)\n",
        "    self.linear=nn.Linear(hidden_dim,output_dim)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.embedding(x)\n",
        "    output,hidden=self.lstm(x)\n",
        "    x=hidden[-1]\n",
        "    y=self.linear(x)\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYfZdXXttK6Z",
        "outputId": "9860bf7f-7e5e-45b5-eead-6a46c1bda753"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "print(torch.version.cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "5xiNHdNouU2N"
      },
      "outputs": [],
      "source": [
        "model=Lstm_model(len(vocab),128,64).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xedaYOoSMf-T",
        "outputId": "80fc5275-e5e9-4829-c580-4c4a9714027e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Lstm_model(\n",
              "  (embedding): Embedding(40048, 128)\n",
              "  (lstm): LSTM(128, 64, batch_first=True)\n",
              "  (linear): Linear(in_features=64, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "pT8fdSPmwQSl"
      },
      "outputs": [],
      "source": [
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.Adam(model.parameters(),lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(),'test_model.pth')\n",
        "model=torch.load('test_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('embedding.weight',\n",
              "              tensor([[ 0.5657, -0.2033,  0.9762,  ...,  1.3672, -0.0592, -0.1217],\n",
              "                      [ 0.8330, -0.8660, -0.7411,  ...,  0.1279,  0.5706, -0.2426],\n",
              "                      [ 2.2252,  0.8623,  0.3364,  ...,  1.5675, -1.4890,  1.1445],\n",
              "                      ...,\n",
              "                      [-1.0010,  0.4126, -0.1223,  ..., -1.9169, -0.8434,  0.7872],\n",
              "                      [ 0.2524, -1.2508, -0.4507,  ..., -1.0283,  1.5766,  1.5063],\n",
              "                      [-0.7897,  0.3919, -0.3935,  ..., -1.2055,  1.9897, -0.1641]])),\n",
              "             ('lstm.weight_ih_l0',\n",
              "              tensor([[-0.0047, -0.0073,  0.0805,  ...,  0.0380, -0.0222,  0.0523],\n",
              "                      [ 0.0740, -0.0387,  0.0984,  ..., -0.1107,  0.0856, -0.0548],\n",
              "                      [ 0.0318,  0.0696, -0.0917,  ..., -0.0095, -0.0438, -0.1196],\n",
              "                      ...,\n",
              "                      [ 0.0208,  0.0491,  0.0593,  ...,  0.0476, -0.1202,  0.0463],\n",
              "                      [-0.1019,  0.0905,  0.0285,  ...,  0.0554, -0.0941,  0.0638],\n",
              "                      [ 0.0507, -0.0454, -0.0900,  ...,  0.0634,  0.0129,  0.0647]])),\n",
              "             ('lstm.weight_hh_l0',\n",
              "              tensor([[-0.0536,  0.0595,  0.0883,  ..., -0.0416,  0.0467,  0.1062],\n",
              "                      [-0.0037, -0.0976, -0.0955,  ..., -0.0675,  0.0615,  0.0236],\n",
              "                      [ 0.0588,  0.0066, -0.0885,  ..., -0.0119, -0.0815, -0.0560],\n",
              "                      ...,\n",
              "                      [-0.1049,  0.0034,  0.0983,  ...,  0.0057, -0.0630,  0.0094],\n",
              "                      [-0.0334, -0.0330,  0.0930,  ..., -0.0383, -0.1109, -0.0590],\n",
              "                      [-0.1245,  0.0680,  0.0582,  ..., -0.0353,  0.0447,  0.0930]])),\n",
              "             ('lstm.bias_ih_l0',\n",
              "              tensor([-0.0950, -0.0233,  0.0781,  0.0473, -0.0236, -0.1063,  0.0160,  0.0144,\n",
              "                      -0.0205, -0.1004, -0.1227, -0.0453,  0.0613,  0.0021,  0.1196,  0.1224,\n",
              "                       0.0106, -0.1198, -0.0039,  0.0955,  0.0334,  0.0630,  0.1018,  0.0203,\n",
              "                      -0.1083, -0.0346, -0.0696, -0.0600,  0.0755,  0.0587, -0.0908, -0.1185,\n",
              "                       0.0279,  0.0154, -0.0888, -0.0569,  0.1035, -0.1150, -0.0960,  0.0508,\n",
              "                       0.0795,  0.0489,  0.1200, -0.0516,  0.1152,  0.0308, -0.0096, -0.0561,\n",
              "                      -0.0810,  0.0906, -0.0956,  0.0513,  0.0905,  0.0725,  0.0741, -0.0517,\n",
              "                      -0.0090, -0.0298,  0.0485, -0.0025, -0.0915, -0.0223,  0.0304, -0.0303,\n",
              "                      -0.0462,  0.0452, -0.0528,  0.0364, -0.0195,  0.0941,  0.0364,  0.0791,\n",
              "                       0.0979, -0.0825,  0.0208, -0.0952, -0.1045, -0.1054, -0.0484,  0.0824,\n",
              "                      -0.0287, -0.0807, -0.0378,  0.1004,  0.0848,  0.0278, -0.1143,  0.1063,\n",
              "                       0.0453,  0.0967,  0.0009,  0.1048, -0.0200,  0.0072, -0.1136,  0.0983,\n",
              "                      -0.0621,  0.0215, -0.0402, -0.0840,  0.0294, -0.0693,  0.0537,  0.0346,\n",
              "                       0.0927,  0.0725,  0.0535,  0.1165,  0.0651, -0.0183, -0.0606, -0.0472,\n",
              "                       0.0964, -0.1111,  0.1116, -0.0025,  0.1120, -0.0333,  0.0569, -0.0894,\n",
              "                       0.0296,  0.1196, -0.0393, -0.1226,  0.0830, -0.0446,  0.0293,  0.0432,\n",
              "                       0.0614, -0.0372, -0.0211, -0.0957, -0.0314, -0.0199, -0.0894, -0.0250,\n",
              "                       0.0659, -0.0984,  0.0762, -0.0353, -0.0761,  0.0787, -0.0653,  0.0163,\n",
              "                       0.0853,  0.0748,  0.0533, -0.0762,  0.1139, -0.0302,  0.0448,  0.0146,\n",
              "                       0.0703,  0.0928, -0.0957, -0.1046, -0.0445, -0.0258, -0.0256, -0.0284,\n",
              "                       0.0589,  0.0346,  0.0181,  0.0303, -0.0059,  0.1138, -0.1152,  0.0732,\n",
              "                       0.0749,  0.0812, -0.0504,  0.0554, -0.0637, -0.0649, -0.0983, -0.0729,\n",
              "                       0.1085,  0.0288,  0.0839, -0.0507,  0.0246,  0.0466,  0.1025, -0.0446,\n",
              "                       0.1195,  0.0194, -0.0846,  0.1223, -0.0133, -0.0331, -0.1109,  0.1057,\n",
              "                       0.0434, -0.0661,  0.0565, -0.0899, -0.1156, -0.0247,  0.0383, -0.0094,\n",
              "                      -0.1185,  0.1028, -0.0655,  0.0568, -0.0436,  0.0376,  0.0710,  0.0561,\n",
              "                      -0.1121,  0.0972,  0.0484, -0.0029,  0.0114, -0.0702,  0.0557, -0.0657,\n",
              "                      -0.0892, -0.0107,  0.0171,  0.0935, -0.0547, -0.1196,  0.0111,  0.1177,\n",
              "                      -0.0790,  0.0084, -0.0232, -0.0410, -0.1219,  0.0542, -0.0821,  0.0885,\n",
              "                      -0.0094, -0.0462,  0.0889,  0.0164,  0.0571,  0.0235,  0.0603, -0.0364,\n",
              "                       0.0196,  0.0572, -0.1188, -0.0271, -0.0500,  0.0261, -0.0212, -0.0429,\n",
              "                       0.0332, -0.0654,  0.0989, -0.0512,  0.0491,  0.0866,  0.0597,  0.0331])),\n",
              "             ('lstm.bias_hh_l0',\n",
              "              tensor([ 0.0610, -0.0442, -0.0833, -0.0787, -0.0813,  0.0323,  0.0985, -0.0144,\n",
              "                      -0.0539,  0.0484,  0.1171, -0.0918, -0.1180, -0.0469,  0.0961, -0.0902,\n",
              "                       0.0317, -0.0931, -0.0822, -0.0645,  0.0214,  0.0855, -0.0568,  0.0733,\n",
              "                      -0.0088, -0.1224,  0.0224, -0.0605,  0.1120,  0.0505,  0.0514, -0.0989,\n",
              "                       0.0988, -0.1046,  0.1221,  0.1099, -0.0371,  0.0902,  0.0989,  0.0664,\n",
              "                       0.0215, -0.0613, -0.0857, -0.0755,  0.0913, -0.0797,  0.1119,  0.0460,\n",
              "                      -0.1176,  0.0155,  0.0449,  0.0638,  0.1125, -0.0693,  0.0680, -0.0246,\n",
              "                       0.1171,  0.1114, -0.0178,  0.1069, -0.1038, -0.0937, -0.1132,  0.0256,\n",
              "                       0.0648,  0.0733, -0.0523,  0.0788, -0.0026, -0.0709, -0.0724, -0.0305,\n",
              "                       0.0970, -0.0072, -0.0605,  0.0040,  0.0268,  0.0302,  0.1209, -0.1238,\n",
              "                      -0.1154, -0.0938, -0.1079, -0.0974, -0.1101,  0.0361,  0.1162,  0.0946,\n",
              "                      -0.0671,  0.1226, -0.0395,  0.0704, -0.0733, -0.0625,  0.1210, -0.1060,\n",
              "                       0.0905, -0.0104,  0.1105, -0.0689, -0.0242, -0.1176, -0.0349,  0.0049,\n",
              "                       0.0283,  0.1017,  0.1026, -0.0403, -0.0142,  0.0314,  0.1242,  0.1135,\n",
              "                      -0.0530,  0.0790,  0.0461, -0.0774,  0.0012,  0.0644, -0.0741,  0.0023,\n",
              "                      -0.1248, -0.0201,  0.1184, -0.1182,  0.0575,  0.0413,  0.0761, -0.0430,\n",
              "                      -0.0598,  0.0363,  0.1030, -0.0451, -0.1086, -0.0723,  0.0116,  0.0431,\n",
              "                       0.0874,  0.0196,  0.0934, -0.1000,  0.0866,  0.0756, -0.0959, -0.0039,\n",
              "                       0.0116, -0.0891, -0.0808,  0.0143,  0.0558, -0.1042,  0.1100,  0.0293,\n",
              "                       0.0831, -0.0525, -0.0751, -0.1236, -0.0072, -0.0400, -0.0125,  0.1213,\n",
              "                       0.0304,  0.0631,  0.0339, -0.0738,  0.0711, -0.1050,  0.0051, -0.0643,\n",
              "                      -0.0912, -0.0912, -0.0537, -0.0193,  0.1224,  0.0252, -0.0724,  0.1094,\n",
              "                      -0.0599,  0.0627,  0.0345, -0.1222,  0.0612,  0.1042,  0.0886, -0.0003,\n",
              "                       0.0424,  0.0262,  0.0968,  0.0779,  0.0868,  0.0754,  0.0759, -0.0395,\n",
              "                      -0.1094, -0.1029,  0.0823,  0.0206,  0.0265, -0.0172, -0.0464, -0.1212,\n",
              "                       0.0583,  0.1120,  0.1160, -0.0044,  0.0614, -0.0187, -0.0243,  0.1170,\n",
              "                       0.0934,  0.1069, -0.1239, -0.1211,  0.0429,  0.0766, -0.0016,  0.0110,\n",
              "                      -0.0899, -0.1187, -0.0308, -0.1074, -0.0867,  0.0273,  0.0262,  0.0116,\n",
              "                       0.0362, -0.0782,  0.0551, -0.0347, -0.0657,  0.1012, -0.0439,  0.1133,\n",
              "                      -0.1151,  0.1150, -0.0972, -0.1218, -0.0010,  0.0296, -0.1168, -0.1041,\n",
              "                      -0.0785,  0.0400,  0.0687, -0.1129, -0.0708, -0.1245, -0.0424,  0.0578,\n",
              "                       0.1143, -0.0956, -0.0557,  0.1141, -0.0041, -0.0693, -0.1211,  0.0801])),\n",
              "             ('linear.weight',\n",
              "              tensor([[-0.0409, -0.0389,  0.0513,  0.0565, -0.0818,  0.0233, -0.0055,  0.0097,\n",
              "                        0.0576,  0.0114,  0.0168,  0.0956,  0.0271,  0.0780, -0.1056,  0.0724,\n",
              "                        0.0363,  0.0652, -0.0035,  0.0748, -0.1104, -0.0249,  0.0913, -0.0734,\n",
              "                       -0.1099, -0.1003,  0.0273,  0.0555,  0.0137, -0.0759,  0.0080, -0.1207,\n",
              "                        0.0407, -0.0148, -0.1043,  0.0834, -0.1186, -0.1138, -0.0564, -0.1004,\n",
              "                        0.0916, -0.0995, -0.0057,  0.0040, -0.0504, -0.0212,  0.0306,  0.0664,\n",
              "                       -0.0137,  0.0761,  0.1102,  0.0995,  0.0274, -0.0252,  0.0434,  0.1018,\n",
              "                       -0.0425, -0.1001,  0.1175,  0.0757, -0.0225, -0.0415, -0.1005, -0.0333],\n",
              "                      [ 0.0016, -0.0026, -0.1003, -0.1209, -0.1182, -0.0752,  0.0762, -0.1159,\n",
              "                       -0.0562,  0.0510, -0.0896,  0.0056,  0.1023,  0.0436,  0.0757,  0.0141,\n",
              "                       -0.0198, -0.0296,  0.0095, -0.0699, -0.0212, -0.1148, -0.0061,  0.1240,\n",
              "                        0.0653,  0.0735, -0.0723, -0.0557, -0.0663, -0.0039, -0.0552, -0.0317,\n",
              "                       -0.0924,  0.0344,  0.0640,  0.1061,  0.0890,  0.0646,  0.0805, -0.1097,\n",
              "                       -0.0993, -0.1188,  0.0082, -0.0126, -0.0576,  0.0639,  0.0509,  0.1053,\n",
              "                        0.0744,  0.0344, -0.0326,  0.0810, -0.0910, -0.0487, -0.0443, -0.1206,\n",
              "                        0.0190,  0.0572,  0.0161, -0.0429, -0.0425,  0.0056,  0.0545,  0.1224],\n",
              "                      [ 0.0360, -0.0682, -0.1052,  0.0657, -0.0358, -0.0410, -0.0552,  0.0677,\n",
              "                        0.1240, -0.0898,  0.1186, -0.0645,  0.0938,  0.0771,  0.0335, -0.0168,\n",
              "                        0.1051,  0.0762, -0.1058, -0.0997, -0.0157, -0.0904, -0.0874,  0.0743,\n",
              "                       -0.0296, -0.0983,  0.0598, -0.0820,  0.1064, -0.0807, -0.0344,  0.1105,\n",
              "                        0.0374,  0.1083, -0.0229,  0.1013,  0.1164,  0.0249,  0.0598,  0.0647,\n",
              "                       -0.0842, -0.1083,  0.0791, -0.0576,  0.0416,  0.0957,  0.0696,  0.1229,\n",
              "                        0.0284,  0.1069,  0.0466, -0.0119,  0.0157, -0.0358, -0.1200,  0.0689,\n",
              "                        0.1074,  0.0300,  0.1080,  0.1241, -0.0008,  0.0275,  0.1168, -0.0339]])),\n",
              "             ('linear.bias', tensor([ 0.0558, -0.0231,  0.0638]))])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model=torch.load('test_model.pth',weights_only=True)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lm_model=Lstm_model(len(vocab),128,64).to(device)\n",
        "lm_model.load_state_dict(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('embedding.weight',\n",
              "              tensor([[ 0.5657, -0.2033,  0.9762,  ...,  1.3672, -0.0592, -0.1217],\n",
              "                      [ 0.8330, -0.8660, -0.7411,  ...,  0.1279,  0.5706, -0.2426],\n",
              "                      [ 2.2252,  0.8623,  0.3364,  ...,  1.5675, -1.4890,  1.1445],\n",
              "                      ...,\n",
              "                      [-1.0010,  0.4126, -0.1223,  ..., -1.9169, -0.8434,  0.7872],\n",
              "                      [ 0.2524, -1.2508, -0.4507,  ..., -1.0283,  1.5766,  1.5063],\n",
              "                      [-0.7897,  0.3919, -0.3935,  ..., -1.2055,  1.9897, -0.1641]])),\n",
              "             ('lstm.weight_ih_l0',\n",
              "              tensor([[-0.0047, -0.0073,  0.0805,  ...,  0.0380, -0.0222,  0.0523],\n",
              "                      [ 0.0740, -0.0387,  0.0984,  ..., -0.1107,  0.0856, -0.0548],\n",
              "                      [ 0.0318,  0.0696, -0.0917,  ..., -0.0095, -0.0438, -0.1196],\n",
              "                      ...,\n",
              "                      [ 0.0208,  0.0491,  0.0593,  ...,  0.0476, -0.1202,  0.0463],\n",
              "                      [-0.1019,  0.0905,  0.0285,  ...,  0.0554, -0.0941,  0.0638],\n",
              "                      [ 0.0507, -0.0454, -0.0900,  ...,  0.0634,  0.0129,  0.0647]])),\n",
              "             ('lstm.weight_hh_l0',\n",
              "              tensor([[-0.0536,  0.0595,  0.0883,  ..., -0.0416,  0.0467,  0.1062],\n",
              "                      [-0.0037, -0.0976, -0.0955,  ..., -0.0675,  0.0615,  0.0236],\n",
              "                      [ 0.0588,  0.0066, -0.0885,  ..., -0.0119, -0.0815, -0.0560],\n",
              "                      ...,\n",
              "                      [-0.1049,  0.0034,  0.0983,  ...,  0.0057, -0.0630,  0.0094],\n",
              "                      [-0.0334, -0.0330,  0.0930,  ..., -0.0383, -0.1109, -0.0590],\n",
              "                      [-0.1245,  0.0680,  0.0582,  ..., -0.0353,  0.0447,  0.0930]])),\n",
              "             ('lstm.bias_ih_l0',\n",
              "              tensor([-0.0950, -0.0233,  0.0781,  0.0473, -0.0236, -0.1063,  0.0160,  0.0144,\n",
              "                      -0.0205, -0.1004, -0.1227, -0.0453,  0.0613,  0.0021,  0.1196,  0.1224,\n",
              "                       0.0106, -0.1198, -0.0039,  0.0955,  0.0334,  0.0630,  0.1018,  0.0203,\n",
              "                      -0.1083, -0.0346, -0.0696, -0.0600,  0.0755,  0.0587, -0.0908, -0.1185,\n",
              "                       0.0279,  0.0154, -0.0888, -0.0569,  0.1035, -0.1150, -0.0960,  0.0508,\n",
              "                       0.0795,  0.0489,  0.1200, -0.0516,  0.1152,  0.0308, -0.0096, -0.0561,\n",
              "                      -0.0810,  0.0906, -0.0956,  0.0513,  0.0905,  0.0725,  0.0741, -0.0517,\n",
              "                      -0.0090, -0.0298,  0.0485, -0.0025, -0.0915, -0.0223,  0.0304, -0.0303,\n",
              "                      -0.0462,  0.0452, -0.0528,  0.0364, -0.0195,  0.0941,  0.0364,  0.0791,\n",
              "                       0.0979, -0.0825,  0.0208, -0.0952, -0.1045, -0.1054, -0.0484,  0.0824,\n",
              "                      -0.0287, -0.0807, -0.0378,  0.1004,  0.0848,  0.0278, -0.1143,  0.1063,\n",
              "                       0.0453,  0.0967,  0.0009,  0.1048, -0.0200,  0.0072, -0.1136,  0.0983,\n",
              "                      -0.0621,  0.0215, -0.0402, -0.0840,  0.0294, -0.0693,  0.0537,  0.0346,\n",
              "                       0.0927,  0.0725,  0.0535,  0.1165,  0.0651, -0.0183, -0.0606, -0.0472,\n",
              "                       0.0964, -0.1111,  0.1116, -0.0025,  0.1120, -0.0333,  0.0569, -0.0894,\n",
              "                       0.0296,  0.1196, -0.0393, -0.1226,  0.0830, -0.0446,  0.0293,  0.0432,\n",
              "                       0.0614, -0.0372, -0.0211, -0.0957, -0.0314, -0.0199, -0.0894, -0.0250,\n",
              "                       0.0659, -0.0984,  0.0762, -0.0353, -0.0761,  0.0787, -0.0653,  0.0163,\n",
              "                       0.0853,  0.0748,  0.0533, -0.0762,  0.1139, -0.0302,  0.0448,  0.0146,\n",
              "                       0.0703,  0.0928, -0.0957, -0.1046, -0.0445, -0.0258, -0.0256, -0.0284,\n",
              "                       0.0589,  0.0346,  0.0181,  0.0303, -0.0059,  0.1138, -0.1152,  0.0732,\n",
              "                       0.0749,  0.0812, -0.0504,  0.0554, -0.0637, -0.0649, -0.0983, -0.0729,\n",
              "                       0.1085,  0.0288,  0.0839, -0.0507,  0.0246,  0.0466,  0.1025, -0.0446,\n",
              "                       0.1195,  0.0194, -0.0846,  0.1223, -0.0133, -0.0331, -0.1109,  0.1057,\n",
              "                       0.0434, -0.0661,  0.0565, -0.0899, -0.1156, -0.0247,  0.0383, -0.0094,\n",
              "                      -0.1185,  0.1028, -0.0655,  0.0568, -0.0436,  0.0376,  0.0710,  0.0561,\n",
              "                      -0.1121,  0.0972,  0.0484, -0.0029,  0.0114, -0.0702,  0.0557, -0.0657,\n",
              "                      -0.0892, -0.0107,  0.0171,  0.0935, -0.0547, -0.1196,  0.0111,  0.1177,\n",
              "                      -0.0790,  0.0084, -0.0232, -0.0410, -0.1219,  0.0542, -0.0821,  0.0885,\n",
              "                      -0.0094, -0.0462,  0.0889,  0.0164,  0.0571,  0.0235,  0.0603, -0.0364,\n",
              "                       0.0196,  0.0572, -0.1188, -0.0271, -0.0500,  0.0261, -0.0212, -0.0429,\n",
              "                       0.0332, -0.0654,  0.0989, -0.0512,  0.0491,  0.0866,  0.0597,  0.0331])),\n",
              "             ('lstm.bias_hh_l0',\n",
              "              tensor([ 0.0610, -0.0442, -0.0833, -0.0787, -0.0813,  0.0323,  0.0985, -0.0144,\n",
              "                      -0.0539,  0.0484,  0.1171, -0.0918, -0.1180, -0.0469,  0.0961, -0.0902,\n",
              "                       0.0317, -0.0931, -0.0822, -0.0645,  0.0214,  0.0855, -0.0568,  0.0733,\n",
              "                      -0.0088, -0.1224,  0.0224, -0.0605,  0.1120,  0.0505,  0.0514, -0.0989,\n",
              "                       0.0988, -0.1046,  0.1221,  0.1099, -0.0371,  0.0902,  0.0989,  0.0664,\n",
              "                       0.0215, -0.0613, -0.0857, -0.0755,  0.0913, -0.0797,  0.1119,  0.0460,\n",
              "                      -0.1176,  0.0155,  0.0449,  0.0638,  0.1125, -0.0693,  0.0680, -0.0246,\n",
              "                       0.1171,  0.1114, -0.0178,  0.1069, -0.1038, -0.0937, -0.1132,  0.0256,\n",
              "                       0.0648,  0.0733, -0.0523,  0.0788, -0.0026, -0.0709, -0.0724, -0.0305,\n",
              "                       0.0970, -0.0072, -0.0605,  0.0040,  0.0268,  0.0302,  0.1209, -0.1238,\n",
              "                      -0.1154, -0.0938, -0.1079, -0.0974, -0.1101,  0.0361,  0.1162,  0.0946,\n",
              "                      -0.0671,  0.1226, -0.0395,  0.0704, -0.0733, -0.0625,  0.1210, -0.1060,\n",
              "                       0.0905, -0.0104,  0.1105, -0.0689, -0.0242, -0.1176, -0.0349,  0.0049,\n",
              "                       0.0283,  0.1017,  0.1026, -0.0403, -0.0142,  0.0314,  0.1242,  0.1135,\n",
              "                      -0.0530,  0.0790,  0.0461, -0.0774,  0.0012,  0.0644, -0.0741,  0.0023,\n",
              "                      -0.1248, -0.0201,  0.1184, -0.1182,  0.0575,  0.0413,  0.0761, -0.0430,\n",
              "                      -0.0598,  0.0363,  0.1030, -0.0451, -0.1086, -0.0723,  0.0116,  0.0431,\n",
              "                       0.0874,  0.0196,  0.0934, -0.1000,  0.0866,  0.0756, -0.0959, -0.0039,\n",
              "                       0.0116, -0.0891, -0.0808,  0.0143,  0.0558, -0.1042,  0.1100,  0.0293,\n",
              "                       0.0831, -0.0525, -0.0751, -0.1236, -0.0072, -0.0400, -0.0125,  0.1213,\n",
              "                       0.0304,  0.0631,  0.0339, -0.0738,  0.0711, -0.1050,  0.0051, -0.0643,\n",
              "                      -0.0912, -0.0912, -0.0537, -0.0193,  0.1224,  0.0252, -0.0724,  0.1094,\n",
              "                      -0.0599,  0.0627,  0.0345, -0.1222,  0.0612,  0.1042,  0.0886, -0.0003,\n",
              "                       0.0424,  0.0262,  0.0968,  0.0779,  0.0868,  0.0754,  0.0759, -0.0395,\n",
              "                      -0.1094, -0.1029,  0.0823,  0.0206,  0.0265, -0.0172, -0.0464, -0.1212,\n",
              "                       0.0583,  0.1120,  0.1160, -0.0044,  0.0614, -0.0187, -0.0243,  0.1170,\n",
              "                       0.0934,  0.1069, -0.1239, -0.1211,  0.0429,  0.0766, -0.0016,  0.0110,\n",
              "                      -0.0899, -0.1187, -0.0308, -0.1074, -0.0867,  0.0273,  0.0262,  0.0116,\n",
              "                       0.0362, -0.0782,  0.0551, -0.0347, -0.0657,  0.1012, -0.0439,  0.1133,\n",
              "                      -0.1151,  0.1150, -0.0972, -0.1218, -0.0010,  0.0296, -0.1168, -0.1041,\n",
              "                      -0.0785,  0.0400,  0.0687, -0.1129, -0.0708, -0.1245, -0.0424,  0.0578,\n",
              "                       0.1143, -0.0956, -0.0557,  0.1141, -0.0041, -0.0693, -0.1211,  0.0801])),\n",
              "             ('linear.weight',\n",
              "              tensor([[-0.0409, -0.0389,  0.0513,  0.0565, -0.0818,  0.0233, -0.0055,  0.0097,\n",
              "                        0.0576,  0.0114,  0.0168,  0.0956,  0.0271,  0.0780, -0.1056,  0.0724,\n",
              "                        0.0363,  0.0652, -0.0035,  0.0748, -0.1104, -0.0249,  0.0913, -0.0734,\n",
              "                       -0.1099, -0.1003,  0.0273,  0.0555,  0.0137, -0.0759,  0.0080, -0.1207,\n",
              "                        0.0407, -0.0148, -0.1043,  0.0834, -0.1186, -0.1138, -0.0564, -0.1004,\n",
              "                        0.0916, -0.0995, -0.0057,  0.0040, -0.0504, -0.0212,  0.0306,  0.0664,\n",
              "                       -0.0137,  0.0761,  0.1102,  0.0995,  0.0274, -0.0252,  0.0434,  0.1018,\n",
              "                       -0.0425, -0.1001,  0.1175,  0.0757, -0.0225, -0.0415, -0.1005, -0.0333],\n",
              "                      [ 0.0016, -0.0026, -0.1003, -0.1209, -0.1182, -0.0752,  0.0762, -0.1159,\n",
              "                       -0.0562,  0.0510, -0.0896,  0.0056,  0.1023,  0.0436,  0.0757,  0.0141,\n",
              "                       -0.0198, -0.0296,  0.0095, -0.0699, -0.0212, -0.1148, -0.0061,  0.1240,\n",
              "                        0.0653,  0.0735, -0.0723, -0.0557, -0.0663, -0.0039, -0.0552, -0.0317,\n",
              "                       -0.0924,  0.0344,  0.0640,  0.1061,  0.0890,  0.0646,  0.0805, -0.1097,\n",
              "                       -0.0993, -0.1188,  0.0082, -0.0126, -0.0576,  0.0639,  0.0509,  0.1053,\n",
              "                        0.0744,  0.0344, -0.0326,  0.0810, -0.0910, -0.0487, -0.0443, -0.1206,\n",
              "                        0.0190,  0.0572,  0.0161, -0.0429, -0.0425,  0.0056,  0.0545,  0.1224],\n",
              "                      [ 0.0360, -0.0682, -0.1052,  0.0657, -0.0358, -0.0410, -0.0552,  0.0677,\n",
              "                        0.1240, -0.0898,  0.1186, -0.0645,  0.0938,  0.0771,  0.0335, -0.0168,\n",
              "                        0.1051,  0.0762, -0.1058, -0.0997, -0.0157, -0.0904, -0.0874,  0.0743,\n",
              "                       -0.0296, -0.0983,  0.0598, -0.0820,  0.1064, -0.0807, -0.0344,  0.1105,\n",
              "                        0.0374,  0.1083, -0.0229,  0.1013,  0.1164,  0.0249,  0.0598,  0.0647,\n",
              "                       -0.0842, -0.1083,  0.0791, -0.0576,  0.0416,  0.0957,  0.0696,  0.1229,\n",
              "                        0.0284,  0.1069,  0.0466, -0.0119,  0.0157, -0.0358, -0.1200,  0.0689,\n",
              "                        0.1074,  0.0300,  0.1080,  0.1241, -0.0008,  0.0275,  0.1168, -0.0339]])),\n",
              "             ('linear.bias', tensor([ 0.0558, -0.0231,  0.0638]))])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lm_model.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "d7HHD8VxjH2O"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "load() takes 1 positional argument but 2 were given",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      2\u001b[39m model_dict={\u001b[33m\"\u001b[39m\u001b[33mkey1\u001b[39m\u001b[33m\"\u001b[39m:\u001b[32m12\u001b[39m}\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mw\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mTypeError\u001b[39m: load() takes 1 positional argument but 2 were given"
          ]
        }
      ],
      "source": [
        "import json\n",
        "model_dict={\"key1\":12}\n",
        "json.load(model_dict,open(\"test.json\",\"w\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKbsFNFIwWVQ",
        "outputId": "d3325b68-c052-46f8-b615-37ebbd57e0f4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 533/6546 [01:00<11:22,  8.81it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m y_pred=y_pred.view(batch_size,output_dim)\n\u001b[32m      9\u001b[39m loss=criterion(y_pred,y)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m loss.backward()\n\u001b[32m     12\u001b[39m optimizer.step()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlflow/lib/python3.12/site-packages/torch/_compile.py:41\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[33;03mThis API should be only used inside torch, external users should still use\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[33;03mtorch._dynamo.disable. The main goal of this API is to avoid circular\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m \u001b[33;03mthe invocation of the decorated function.\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;129m@functools\u001b[39m.wraps(fn)\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args: _P.args, **kwargs: _P.kwargs) -> _T:\n\u001b[32m     43\u001b[39m         \u001b[38;5;66;03m# cache this on the first invocation to avoid adding too much overhead.\u001b[39;00m\n\u001b[32m     44\u001b[39m         disable_fn = \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[33m\"\u001b[39m\u001b[33m__dynamo_disable\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     45\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m disable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "for epoch in range(25):\n",
        "  total_loss=0\n",
        "  for x,y in tqdm(train_dataloader):\n",
        "    y_pred=model(x)\n",
        "    y_pred=y_pred.squeeze()\n",
        "    batch_size=y.shape[0]\n",
        "    y_pred=y_pred.view(batch_size,output_dim)\n",
        "    loss=criterion(y_pred,y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss+=loss.item()\n",
        "  print(f\"Loss for epoch-{epoch} is\", total_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path=\"/Users/keertan.patro/Desktop/Practice/Yt_sentiment_analysis/lstm_model.pth\"\n",
        "torch.save(model,model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('embedding.weight',\n",
              "              tensor([[ 0.5657, -0.2033,  0.9762,  ...,  1.3672, -0.0592, -0.1217],\n",
              "                      [ 0.8330, -0.8660, -0.7411,  ...,  0.1279,  0.5706, -0.2426],\n",
              "                      [ 2.2252,  0.8623,  0.3364,  ...,  1.5675, -1.4890,  1.1445],\n",
              "                      ...,\n",
              "                      [-1.0010,  0.4126, -0.1223,  ..., -1.9169, -0.8434,  0.7872],\n",
              "                      [ 0.2524, -1.2508, -0.4507,  ..., -1.0283,  1.5766,  1.5063],\n",
              "                      [-0.7897,  0.3919, -0.3935,  ..., -1.2055,  1.9897, -0.1641]])),\n",
              "             ('lstm.weight_ih_l0',\n",
              "              tensor([[-0.0047, -0.0073,  0.0805,  ...,  0.0380, -0.0222,  0.0523],\n",
              "                      [ 0.0740, -0.0387,  0.0984,  ..., -0.1107,  0.0856, -0.0548],\n",
              "                      [ 0.0318,  0.0696, -0.0917,  ..., -0.0095, -0.0438, -0.1196],\n",
              "                      ...,\n",
              "                      [ 0.0208,  0.0491,  0.0593,  ...,  0.0476, -0.1202,  0.0463],\n",
              "                      [-0.1019,  0.0905,  0.0285,  ...,  0.0554, -0.0941,  0.0638],\n",
              "                      [ 0.0507, -0.0454, -0.0900,  ...,  0.0634,  0.0129,  0.0647]])),\n",
              "             ('lstm.weight_hh_l0',\n",
              "              tensor([[-0.0536,  0.0595,  0.0883,  ..., -0.0416,  0.0467,  0.1062],\n",
              "                      [-0.0037, -0.0976, -0.0955,  ..., -0.0675,  0.0615,  0.0236],\n",
              "                      [ 0.0588,  0.0066, -0.0885,  ..., -0.0119, -0.0815, -0.0560],\n",
              "                      ...,\n",
              "                      [-0.1049,  0.0034,  0.0983,  ...,  0.0057, -0.0630,  0.0094],\n",
              "                      [-0.0334, -0.0330,  0.0930,  ..., -0.0383, -0.1109, -0.0590],\n",
              "                      [-0.1245,  0.0680,  0.0582,  ..., -0.0353,  0.0447,  0.0930]])),\n",
              "             ('lstm.bias_ih_l0',\n",
              "              tensor([-0.0950, -0.0233,  0.0781,  0.0473, -0.0236, -0.1063,  0.0160,  0.0144,\n",
              "                      -0.0205, -0.1004, -0.1227, -0.0453,  0.0613,  0.0021,  0.1196,  0.1224,\n",
              "                       0.0106, -0.1198, -0.0039,  0.0955,  0.0334,  0.0630,  0.1018,  0.0203,\n",
              "                      -0.1083, -0.0346, -0.0696, -0.0600,  0.0755,  0.0587, -0.0908, -0.1185,\n",
              "                       0.0279,  0.0154, -0.0888, -0.0569,  0.1035, -0.1150, -0.0960,  0.0508,\n",
              "                       0.0795,  0.0489,  0.1200, -0.0516,  0.1152,  0.0308, -0.0096, -0.0561,\n",
              "                      -0.0810,  0.0906, -0.0956,  0.0513,  0.0905,  0.0725,  0.0741, -0.0517,\n",
              "                      -0.0090, -0.0298,  0.0485, -0.0025, -0.0915, -0.0223,  0.0304, -0.0303,\n",
              "                      -0.0462,  0.0452, -0.0528,  0.0364, -0.0195,  0.0941,  0.0364,  0.0791,\n",
              "                       0.0979, -0.0825,  0.0208, -0.0952, -0.1045, -0.1054, -0.0484,  0.0824,\n",
              "                      -0.0287, -0.0807, -0.0378,  0.1004,  0.0848,  0.0278, -0.1143,  0.1063,\n",
              "                       0.0453,  0.0967,  0.0009,  0.1048, -0.0200,  0.0072, -0.1136,  0.0983,\n",
              "                      -0.0621,  0.0215, -0.0402, -0.0840,  0.0294, -0.0693,  0.0537,  0.0346,\n",
              "                       0.0927,  0.0725,  0.0535,  0.1165,  0.0651, -0.0183, -0.0606, -0.0472,\n",
              "                       0.0964, -0.1111,  0.1116, -0.0025,  0.1120, -0.0333,  0.0569, -0.0894,\n",
              "                       0.0296,  0.1196, -0.0393, -0.1226,  0.0830, -0.0446,  0.0293,  0.0432,\n",
              "                       0.0614, -0.0372, -0.0211, -0.0957, -0.0314, -0.0199, -0.0894, -0.0250,\n",
              "                       0.0659, -0.0984,  0.0762, -0.0353, -0.0761,  0.0787, -0.0653,  0.0163,\n",
              "                       0.0853,  0.0748,  0.0533, -0.0762,  0.1139, -0.0302,  0.0448,  0.0146,\n",
              "                       0.0703,  0.0928, -0.0957, -0.1046, -0.0445, -0.0258, -0.0256, -0.0284,\n",
              "                       0.0589,  0.0346,  0.0181,  0.0303, -0.0059,  0.1138, -0.1152,  0.0732,\n",
              "                       0.0749,  0.0812, -0.0504,  0.0554, -0.0637, -0.0649, -0.0983, -0.0729,\n",
              "                       0.1085,  0.0288,  0.0839, -0.0507,  0.0246,  0.0466,  0.1025, -0.0446,\n",
              "                       0.1195,  0.0194, -0.0846,  0.1223, -0.0133, -0.0331, -0.1109,  0.1057,\n",
              "                       0.0434, -0.0661,  0.0565, -0.0899, -0.1156, -0.0247,  0.0383, -0.0094,\n",
              "                      -0.1185,  0.1028, -0.0655,  0.0568, -0.0436,  0.0376,  0.0710,  0.0561,\n",
              "                      -0.1121,  0.0972,  0.0484, -0.0029,  0.0114, -0.0702,  0.0557, -0.0657,\n",
              "                      -0.0892, -0.0107,  0.0171,  0.0935, -0.0547, -0.1196,  0.0111,  0.1177,\n",
              "                      -0.0790,  0.0084, -0.0232, -0.0410, -0.1219,  0.0542, -0.0821,  0.0885,\n",
              "                      -0.0094, -0.0462,  0.0889,  0.0164,  0.0571,  0.0235,  0.0603, -0.0364,\n",
              "                       0.0196,  0.0572, -0.1188, -0.0271, -0.0500,  0.0261, -0.0212, -0.0429,\n",
              "                       0.0332, -0.0654,  0.0989, -0.0512,  0.0491,  0.0866,  0.0597,  0.0331])),\n",
              "             ('lstm.bias_hh_l0',\n",
              "              tensor([ 0.0610, -0.0442, -0.0833, -0.0787, -0.0813,  0.0323,  0.0985, -0.0144,\n",
              "                      -0.0539,  0.0484,  0.1171, -0.0918, -0.1180, -0.0469,  0.0961, -0.0902,\n",
              "                       0.0317, -0.0931, -0.0822, -0.0645,  0.0214,  0.0855, -0.0568,  0.0733,\n",
              "                      -0.0088, -0.1224,  0.0224, -0.0605,  0.1120,  0.0505,  0.0514, -0.0989,\n",
              "                       0.0988, -0.1046,  0.1221,  0.1099, -0.0371,  0.0902,  0.0989,  0.0664,\n",
              "                       0.0215, -0.0613, -0.0857, -0.0755,  0.0913, -0.0797,  0.1119,  0.0460,\n",
              "                      -0.1176,  0.0155,  0.0449,  0.0638,  0.1125, -0.0693,  0.0680, -0.0246,\n",
              "                       0.1171,  0.1114, -0.0178,  0.1069, -0.1038, -0.0937, -0.1132,  0.0256,\n",
              "                       0.0648,  0.0733, -0.0523,  0.0788, -0.0026, -0.0709, -0.0724, -0.0305,\n",
              "                       0.0970, -0.0072, -0.0605,  0.0040,  0.0268,  0.0302,  0.1209, -0.1238,\n",
              "                      -0.1154, -0.0938, -0.1079, -0.0974, -0.1101,  0.0361,  0.1162,  0.0946,\n",
              "                      -0.0671,  0.1226, -0.0395,  0.0704, -0.0733, -0.0625,  0.1210, -0.1060,\n",
              "                       0.0905, -0.0104,  0.1105, -0.0689, -0.0242, -0.1176, -0.0349,  0.0049,\n",
              "                       0.0283,  0.1017,  0.1026, -0.0403, -0.0142,  0.0314,  0.1242,  0.1135,\n",
              "                      -0.0530,  0.0790,  0.0461, -0.0774,  0.0012,  0.0644, -0.0741,  0.0023,\n",
              "                      -0.1248, -0.0201,  0.1184, -0.1182,  0.0575,  0.0413,  0.0761, -0.0430,\n",
              "                      -0.0598,  0.0363,  0.1030, -0.0451, -0.1086, -0.0723,  0.0116,  0.0431,\n",
              "                       0.0874,  0.0196,  0.0934, -0.1000,  0.0866,  0.0756, -0.0959, -0.0039,\n",
              "                       0.0116, -0.0891, -0.0808,  0.0143,  0.0558, -0.1042,  0.1100,  0.0293,\n",
              "                       0.0831, -0.0525, -0.0751, -0.1236, -0.0072, -0.0400, -0.0125,  0.1213,\n",
              "                       0.0304,  0.0631,  0.0339, -0.0738,  0.0711, -0.1050,  0.0051, -0.0643,\n",
              "                      -0.0912, -0.0912, -0.0537, -0.0193,  0.1224,  0.0252, -0.0724,  0.1094,\n",
              "                      -0.0599,  0.0627,  0.0345, -0.1222,  0.0612,  0.1042,  0.0886, -0.0003,\n",
              "                       0.0424,  0.0262,  0.0968,  0.0779,  0.0868,  0.0754,  0.0759, -0.0395,\n",
              "                      -0.1094, -0.1029,  0.0823,  0.0206,  0.0265, -0.0172, -0.0464, -0.1212,\n",
              "                       0.0583,  0.1120,  0.1160, -0.0044,  0.0614, -0.0187, -0.0243,  0.1170,\n",
              "                       0.0934,  0.1069, -0.1239, -0.1211,  0.0429,  0.0766, -0.0016,  0.0110,\n",
              "                      -0.0899, -0.1187, -0.0308, -0.1074, -0.0867,  0.0273,  0.0262,  0.0116,\n",
              "                       0.0362, -0.0782,  0.0551, -0.0347, -0.0657,  0.1012, -0.0439,  0.1133,\n",
              "                      -0.1151,  0.1150, -0.0972, -0.1218, -0.0010,  0.0296, -0.1168, -0.1041,\n",
              "                      -0.0785,  0.0400,  0.0687, -0.1129, -0.0708, -0.1245, -0.0424,  0.0578,\n",
              "                       0.1143, -0.0956, -0.0557,  0.1141, -0.0041, -0.0693, -0.1211,  0.0801])),\n",
              "             ('linear.weight',\n",
              "              tensor([[-0.0409, -0.0389,  0.0513,  0.0565, -0.0818,  0.0233, -0.0055,  0.0097,\n",
              "                        0.0576,  0.0114,  0.0168,  0.0956,  0.0271,  0.0780, -0.1056,  0.0724,\n",
              "                        0.0363,  0.0652, -0.0035,  0.0748, -0.1104, -0.0249,  0.0913, -0.0734,\n",
              "                       -0.1099, -0.1003,  0.0273,  0.0555,  0.0137, -0.0759,  0.0080, -0.1207,\n",
              "                        0.0407, -0.0148, -0.1043,  0.0834, -0.1186, -0.1138, -0.0564, -0.1004,\n",
              "                        0.0916, -0.0995, -0.0057,  0.0040, -0.0504, -0.0212,  0.0306,  0.0664,\n",
              "                       -0.0137,  0.0761,  0.1102,  0.0995,  0.0274, -0.0252,  0.0434,  0.1018,\n",
              "                       -0.0425, -0.1001,  0.1175,  0.0757, -0.0225, -0.0415, -0.1005, -0.0333],\n",
              "                      [ 0.0016, -0.0026, -0.1003, -0.1209, -0.1182, -0.0752,  0.0762, -0.1159,\n",
              "                       -0.0562,  0.0510, -0.0896,  0.0056,  0.1023,  0.0436,  0.0757,  0.0141,\n",
              "                       -0.0198, -0.0296,  0.0095, -0.0699, -0.0212, -0.1148, -0.0061,  0.1240,\n",
              "                        0.0653,  0.0735, -0.0723, -0.0557, -0.0663, -0.0039, -0.0552, -0.0317,\n",
              "                       -0.0924,  0.0344,  0.0640,  0.1061,  0.0890,  0.0646,  0.0805, -0.1097,\n",
              "                       -0.0993, -0.1188,  0.0082, -0.0126, -0.0576,  0.0639,  0.0509,  0.1053,\n",
              "                        0.0744,  0.0344, -0.0326,  0.0810, -0.0910, -0.0487, -0.0443, -0.1206,\n",
              "                        0.0190,  0.0572,  0.0161, -0.0429, -0.0425,  0.0056,  0.0545,  0.1224],\n",
              "                      [ 0.0360, -0.0682, -0.1052,  0.0657, -0.0358, -0.0410, -0.0552,  0.0677,\n",
              "                        0.1240, -0.0898,  0.1186, -0.0645,  0.0938,  0.0771,  0.0335, -0.0168,\n",
              "                        0.1051,  0.0762, -0.1058, -0.0997, -0.0157, -0.0904, -0.0874,  0.0743,\n",
              "                       -0.0296, -0.0983,  0.0598, -0.0820,  0.1064, -0.0807, -0.0344,  0.1105,\n",
              "                        0.0374,  0.1083, -0.0229,  0.1013,  0.1164,  0.0249,  0.0598,  0.0647,\n",
              "                       -0.0842, -0.1083,  0.0791, -0.0576,  0.0416,  0.0957,  0.0696,  0.1229,\n",
              "                        0.0284,  0.1069,  0.0466, -0.0119,  0.0157, -0.0358, -0.1200,  0.0689,\n",
              "                        0.1074,  0.0300,  0.1080,  0.1241, -0.0008,  0.0275,  0.1168, -0.0339]])),\n",
              "             ('linear.bias', tensor([ 0.0558, -0.0231,  0.0638]))])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "def evaluate_model(model,test_dataloader):\n",
        "  model.eval()\n",
        "  y_pred_all=[]\n",
        "  y_true_all=[]\n",
        "  for x,y in test_dataloader:\n",
        "    y_pred=model(x)\n",
        "    y_pred=torch.max(y_pred,-1).indices.view(y.shape[0])\n",
        "    if y_pred.device.type==\"cuda\":\n",
        "      y_pred=y_pred.to(\"cpu\").tolist()\n",
        "      y=y.to(\"cpu\").tolist()\n",
        "      y_pred_all.extend(y_pred)\n",
        "      y_true_all.extend(y)\n",
        "    elif y_pred.device.type==\"cpu\":\n",
        "      y_pred=y_pred.tolist()\n",
        "      y_pred_all.extend(y_pred)\n",
        "      y=y.tolist()\n",
        "      y_true_all.extend(y)\n",
        "  report=classification_report(y_true_all,y_pred_all,output_dict=True)\n",
        "  return report,y_true_all,y_pred_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "class report: {'0': {'precision': 0.5950834879406308, 'recall': 0.6095011876484561, 'f1-score': 0.6022060549166862, 'support': 2105.0}, '1': {'precision': 0.5347259902333152, 'recall': 0.6768543956043956, 'f1-score': 0.59745377387087, 'support': 2912.0}, '2': {'precision': 0.30113636363636365, 'recall': 0.13865271419228253, 'f1-score': 0.18987908643081056, 'support': 1529.0}, 'accuracy': 0.5294836541399328, 'macro avg': {'precision': 0.4769819472701033, 'recall': 0.4750027658150448, 'f1-score': 0.46317963840612225, 'support': 6546.0}, 'weighted avg': {'precision': 0.4995738352695451, 'recall': 0.5294836541399328, 'f1-score': 0.5037815854360383, 'support': 6546.0}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/10/08 16:20:26 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "\u001b[31m2025/10/08 16:20:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import mlflow\n",
        "import json\n",
        "mlflow.set_tracking_uri(\"http://ec2-52-23-156-179.compute-1.amazonaws.com:5000\")\n",
        "from mlflow.tracking import MlflowClient\n",
        "client=MlflowClient()\n",
        "\n",
        "experiment=client.get_experiment_by_name(\"Yt_analysis\")\n",
        "experiment_id=experiment.experiment_id\n",
        "run = client.create_run(experiment_id=experiment_id)\n",
        "run_id = run.info.run_id\n",
        "\n",
        "class_report,y_true_all,y_pred_all=evaluate_model(model,test_dataloader)\n",
        "print(\"class report:\",class_report)\n",
        "client.log_param(run_id,\"Model\",\"LSTM\")\n",
        "for metric in class_report:\n",
        "    if type(class_report[metric])==dict:\n",
        "        for key in class_report[metric]:\n",
        "            if key!='support':\n",
        "                client.log_metric(run_id,f\"{metric}_{key}\",class_report[metric][key])\n",
        "    else:\n",
        "        client.log_metric(run_id,metric,class_report[metric])\n",
        "model_path=mlflow.pytorch.log_model(model, \"sentiment_model\")\n",
        "model_path=model_path.model_uri\n",
        "with open(\"model_details.json\",\"w\") as f:\n",
        "    details={\n",
        "        \"run_id\":run_id,\n",
        "        \"model_uri\":model_path\n",
        "    }\n",
        "    f.write(json.dumps(details))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/keertan.patro/miniconda3/envs/mlflow/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Downloading artifacts: 100%|██████████| 6/6 [00:08<00:00,  1.44s/it]   \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Lstm_model(\n",
              "  (embedding): Embedding(40048, 128)\n",
              "  (lstm): LSTM(128, 64, batch_first=True)\n",
              "  (linear): Linear(in_features=64, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlflow.pytorch.load_model(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"model_details.json\",\"w\") as f:\n",
        "    details={\n",
        "        \"run_id\":run_id,\n",
        "        \"model_uri\":model_path\n",
        "    }\n",
        "    f.write(json.dumps(details))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'run_id': 'b07cd926f6bb43f5a06b8b7f8dec74b9',\n",
              " 'model_uri': 'models:/m-0112233ec14c45ae91f83ee34eb21881'}"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a=json.load(open(\"model_details.json\",\"r\"))\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_uri=a['model_uri']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Successfully registered model 'sentiment_model'.\n",
            "2025/10/09 00:26:26 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: sentiment_model, version 1\n",
            "Created version '1' of model 'sentiment_model'.\n",
            "/var/folders/hj/pb36nbg93kz0c0dn51ck371w0000gq/T/ipykernel_33670/2369929522.py:2: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
            "  client.transition_model_version_stage(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<ModelVersion: aliases=[], creation_timestamp=1759949786180, current_stage='Production', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1759949789728, metrics=None, model_id=None, name='sentiment_model', params=None, run_id='', run_link='', source='models:/m-0112233ec14c45ae91f83ee34eb21881', status='READY', status_message=None, tags={}, user_id='', version='1'>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mv=mlflow.register_model(model_uri=model_uri,name=\"sentiment_model\")\n",
        "client.transition_model_version_stage(\n",
        "        name=\"sentiment_model\",\n",
        "        version=mv.version,\n",
        "        stage=\"Production\",\n",
        "        archive_existing_versions=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_report,y_true_all,y_pred_all=evaluate_model(model,test_dataloader)\n",
        "print(\"class report:\",class_report)\n",
        "client.log_param(run_id,\"Model\",\"LSTM\")\n",
        "for metric in class_report:\n",
        "    if type(class_report[metric])==dict:\n",
        "        for key in class_report[metric]:\n",
        "            if key!='support':\n",
        "                client.log_metric(run_id,f\"{metric}_{key}\",class_report[metric][key])\n",
        "    else:\n",
        "        client.log_metric(run_id,metric,class_report[metric])\n",
        "model_path=mlflow.pytorch.log_model(model, \"sentiment_model\")\n",
        "model_path=model_path.model_uri\n",
        "with open(\"model_details.json\",\"w\") as f:\n",
        "    details={\n",
        "        \"run_id\":run_id,\n",
        "        \"model_uri\":model_path\n",
        "    }\n",
        "    f.write(json.dumps(details))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "R1daANwNb02Q"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model,test_dataloader):\n",
        "  model.eval()\n",
        "  y_pred_all=[]\n",
        "  y_true_all=[]\n",
        "  for x,y in test_dataloader:\n",
        "    y_pred=model(x)\n",
        "    y_pred=torch.max(y_pred,-1).indices.view(y.shape[0])\n",
        "    if y_pred.device.type==\"cuda\":\n",
        "      y_pred=y_pred.to(\"cpu\").tolist()\n",
        "      y=y.to(\"cpu\").tolist()\n",
        "      y_pred_all.extend(y_pred)\n",
        "      y_true_all.extend(y)\n",
        "    elif y_pred.device.type==\"cpu\":\n",
        "      y_pred=y_pred.tolist()\n",
        "      y_pred_all.extend(y_pred)\n",
        "      y=y.tolist()\n",
        "      y_true_all.extend(y)\n",
        "  report=classification_report(y_true_all,y_pred_all,output_dict=True)\n",
        "  return report,y_true_all,y_pred_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'0': {'precision': 0.5500417014178482,\n",
              "   'recall': 0.626603325415677,\n",
              "   'f1-score': 0.5858316677770375,\n",
              "   'support': 2105.0},\n",
              "  '1': {'precision': 0.5299719887955182,\n",
              "   'recall': 0.6497252747252747,\n",
              "   'f1-score': 0.5837704412218451,\n",
              "   'support': 2912.0},\n",
              "  '2': {'precision': 0.31141868512110726,\n",
              "   'recall': 0.11772400261608895,\n",
              "   'f1-score': 0.170859041290935,\n",
              "   'support': 1529.0},\n",
              "  'accuracy': 0.5180262755881454,\n",
              "  'macro avg': {'precision': 0.4638107917781579,\n",
              "   'recall': 0.4646842009190135,\n",
              "   'f1-score': 0.4468203834299392,\n",
              "   'support': 6546.0},\n",
              "  'weighted avg': {'precision': 0.48537662426020356,\n",
              "   'recall': 0.5180262755881454,\n",
              "   'f1-score': 0.48798635191605816,\n",
              "   'support': 6546.0}},\n",
              " [2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  ...],\n",
              " [1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  ...])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_model(model,test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "PuOTPumu4O4X"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score,recall_score,classification_report\n",
        "import mlflow\n",
        "import boto3\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "load_dotenv()\n",
        "mlflow.set_tracking_uri(\"http://ec2-52-23-156-179.compute-1.amazonaws.com:5000\")\n",
        "# mlflow.set_experiment(\"Yt_analysis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/hj/pb36nbg93kz0c0dn51ck371w0000gq/T/ipykernel_2014/484823568.py:9: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
            "  prod_model=client.get_latest_versions(\"production_model\",stages=['Production'])\n"
          ]
        }
      ],
      "source": [
        "import mlflow.exceptions\n",
        "from mlflow.tracking import MlflowClient\n",
        "import requests\n",
        "\n",
        "client=MlflowClient()\n",
        "experiment=client.get_experiment_by_name(\"Yt_analysis\")\n",
        "experiment_id=experiment.experiment_id\n",
        "try:\n",
        "    prod_model=client.get_latest_versions(\"production_model\",stages=['Production'])\n",
        "except mlflow.exceptions.RestException:\n",
        "    prod_model=None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<ModelVersion: aliases=[], creation_timestamp=1758975840910, current_stage='Production', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1758975848999, metrics=None, model_id=None, name='production_model', params=None, run_id='', run_link='', source='s3://yt-models-1/504809828903330705/208659ab9cef4fc4abcafb5661eaba66/artifacts', status='READY', status_message=None, tags={'model_path': 'models:/m-b25dc550dad8457ea26988622eb03a27'}, user_id='', version='2'>]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prod_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model_uri=\"s3://yt-models-1/504809828903330705/models/m-46a02090a8c142dbbba46dc10e80edbb/artifacts\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# getting top models\n",
        "runs = client.search_runs(\n",
        "    experiment_ids=[experiment_id],\n",
        "    order_by=['Created DESC']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Run: data=<RunData: metrics={'0_f1-score': 0.6130746130746131,\n",
              " '0_precision': 0.5966726618705036,\n",
              " '0_recall': 0.6304038004750594,\n",
              " '1_f1-score': 0.6434385263458517,\n",
              " '1_precision': 0.5507210950867758,\n",
              " '1_recall': 0.773695054945055,\n",
              " '2_f1-score': 0.10454545454545454,\n",
              " '2_precision': 0.39826839826839827,\n",
              " '2_recall': 0.060170045781556575,\n",
              " 'accuracy': 0.5609532538955087,\n",
              " 'macro avg_f1-score': 0.4536861979886398,\n",
              " 'macro avg_precision': 0.5152207184085592,\n",
              " 'macro avg_recall': 0.4880896337338903,\n",
              " 'weighted avg_f1-score': 0.5078009546656249,\n",
              " 'weighted avg_precision': 0.5298882008986376,\n",
              " 'weighted avg_recall': 0.5609532538955087}, params={'Model': 'LSTM'}, tags={'experiment_type': 'algorithmic comparison',\n",
              " 'mlflow.runName': 'LSTM2',\n",
              " 'mlflow.source.name': '/Users/keertan.patro/miniconda3/envs/mlflow/lib/python3.12/site-packages/ipykernel_launcher.py',\n",
              " 'mlflow.source.type': 'LOCAL',\n",
              " 'mlflow.user': 'keertan.patro'}>, info=<RunInfo: artifact_uri='s3://yt-models-1/504809828903330705/208659ab9cef4fc4abcafb5661eaba66/artifacts', end_time=1757265703863, experiment_id='504809828903330705', lifecycle_stage='active', run_id='208659ab9cef4fc4abcafb5661eaba66', run_name='LSTM2', start_time=1757265561935, status='FINISHED', user_id='keertan.patro'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[<LoggedModelOutput: model_id='m-b25dc550dad8457ea26988622eb03a27', step=0>]>>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a=runs[0]\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'208659ab9cef4fc4abcafb5661eaba66'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a.outputs.model_outputs[0].model_id\n",
        "run_id=a.info.run_id\n",
        "run_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/keertan.patro/miniconda3/envs/mlflow/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Downloading artifacts: 100%|██████████| 6/6 [03:44<00:00, 37.43s/it]   \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Lstm_model(\n",
              "  (embedding): Embedding(40048, 128)\n",
              "  (lstm): LSTM(128, 64, batch_first=True)\n",
              "  (linear): Linear(in_features=64, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_id=a.outputs.model_outputs[0].model_id\n",
        "run_id=a.info.run_id\n",
        "def load_latest_model(model_id):\n",
        "    model_uri=f\"models:/{model_id}\"\n",
        "    model=mlflow.pytorch.load_model(model_uri)\n",
        "    return model\n",
        "model=load_latest_model(model_id)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_registered_model(stage):\n",
        "    try:\n",
        "        prod_model=client.get_latest_versions(name=\"production_model\",stages=[stage])\n",
        "    except mlflow.exceptions.RestException:\n",
        "        prod_model=None\n",
        "    return prod_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/hj/pb36nbg93kz0c0dn51ck371w0000gq/T/ipykernel_2014/3881848128.py:3: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
            "  prod_model=client.get_latest_versions(name=\"production_model\",stages=[stage])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<ModelVersion: aliases=[], creation_timestamp=1758975840910, current_stage='Production', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1758975848999, metrics=None, model_id=None, name='production_model', params=None, run_id='', run_link='', source='s3://yt-models-1/504809828903330705/208659ab9cef4fc4abcafb5661eaba66/artifacts', status='READY', status_message=None, tags={'model_path': 'models:/m-b25dc550dad8457ea26988622eb03a27'}, user_id='', version='2'>]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prod_model=check_registered_model(\"Production\")\n",
        "prod_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_uri_new=f\"runs:/{run_id}/LSTM2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def register_model(model_id,experiment_id):\n",
        "    \n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "MlflowException",
          "evalue": "The following failures occurred while downloading one or more artifacts from s3://yt-models-1/504809828903330705/208659ab9cef4fc4abcafb5661eaba66:\n##### File artifacts #####\nAn error occurred (404) when calling the HeadObject operation: Not Found",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mMlflowException\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpytorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m.\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlflow/lib/python3.12/site-packages/mlflow/pytorch/__init__.py:646\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(model_uri, dst_path, **kwargs)\u001b[39m\n\u001b[32m    594\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    595\u001b[39m \u001b[33;03mLoad a PyTorch model from a local file or a run.\u001b[39;00m\n\u001b[32m    596\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    642\u001b[39m \u001b[33;03m    predict X: 30.0, y_pred: 60.48\u001b[39;00m\n\u001b[32m    643\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    644\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m646\u001b[39m local_model_path = \u001b[43m_download_artifact_from_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdst_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    647\u001b[39m pytorch_conf = _get_flavor_configuration(model_path=local_model_path, flavor_name=FLAVOR_NAME)\n\u001b[32m    648\u001b[39m _add_code_from_conf_to_system_path(local_model_path, pytorch_conf)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlflow/lib/python3.12/site-packages/mlflow/tracking/artifact_utils.py:124\u001b[39m, in \u001b[36m_download_artifact_from_uri\u001b[39m\u001b[34m(artifact_uri, output_path, lineage_header_info, tracking_uri)\u001b[39m\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(repo, ModelsArtifactRepository):\n\u001b[32m    119\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m repo.download_artifacts(\n\u001b[32m    120\u001b[39m             artifact_path=artifact_path,\n\u001b[32m    121\u001b[39m             dst_path=output_path,\n\u001b[32m    122\u001b[39m             lineage_header_info=lineage_header_info,\n\u001b[32m    123\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrepo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artifact_uri.startswith(\u001b[33m\"\u001b[39m\u001b[33mm-\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    127\u001b[39m         \u001b[38;5;66;03m# When a Model ID like string is passed, suggest using 'models:/{artifact_uri}' instead.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlflow/lib/python3.12/site-packages/mlflow/store/artifact/artifact_repo.py:323\u001b[39m, in \u001b[36mArtifactRepository.download_artifacts\u001b[39m\u001b[34m(self, artifact_path, dst_path)\u001b[39m\n\u001b[32m    317\u001b[39m         template = \u001b[33m\"\u001b[39m\u001b[33m##### File \u001b[39m\u001b[38;5;132;01m{path}\u001b[39;00m\u001b[33m #####\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{error}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    319\u001b[39m     failures = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(\n\u001b[32m    320\u001b[39m         template.format(path=path, error=error, traceback=tracebacks[path])\n\u001b[32m    321\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m path, error \u001b[38;5;129;01min\u001b[39;00m failed_downloads.items()\n\u001b[32m    322\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m    324\u001b[39m         message=(\n\u001b[32m    325\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe following failures occurred while downloading one or more\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    326\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m artifacts from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.artifact_uri\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_truncate_error(failures)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    327\u001b[39m         )\n\u001b[32m    328\u001b[39m     )\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m os.path.join(dst_path, artifact_path)\n",
            "\u001b[31mMlflowException\u001b[39m: The following failures occurred while downloading one or more artifacts from s3://yt-models-1/504809828903330705/208659ab9cef4fc4abcafb5661eaba66:\n##### File artifacts #####\nAn error occurred (404) when calling the HeadObject operation: Not Found"
          ]
        }
      ],
      "source": [
        "mlflow.pytorch.load_model(a.info.artifact_uri)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name '__file__' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m os.path.abspath(\u001b[34;43m__file__\u001b[39;49m)\n",
            "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.path.abspath(__file__)\n",
        "os.path.dirname(os.path.abspath(__file__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_uri=\"models:/\"+runs[0].outputs.model_outputs[0].model_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/keertan.patro/Desktop/Practice/Yt_sentiment_analysis/Notebooks'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "root_dir = os.path.abspath(os.curdir)\n",
        "root_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model_uri' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel_uri\u001b[49m\n",
            "\u001b[31mNameError\u001b[39m: name 'model_uri' is not defined"
          ]
        }
      ],
      "source": [
        "model_uri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading artifacts: 100%|██████████| 6/6 [00:09<00:00,  1.57s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Lstm_model(\n",
              "  (embedding): Embedding(40048, 128)\n",
              "  (lstm): LSTM(128, 64, batch_first=True)\n",
              "  (linear): Linear(in_features=64, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlflow.pytorch.load_model(model_uri)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Registered model 'production_model' already exists. Creating a new version of this model...\n",
            "2025/09/09 00:51:29 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: production_model, version 2\n",
            "Created version '2' of model 'production_model'.\n",
            "/var/folders/hj/pb36nbg93kz0c0dn51ck371w0000gq/T/ipykernel_44033/3417786407.py:2: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
            "  client.transition_model_version_stage(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<ModelVersion: aliases=[], creation_timestamp=1757359288955, current_stage='Production', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1757359290589, metrics=None, model_id=None, name='production_model', params=None, run_id='', run_link='', source='s3://yt-models-1/504809828903330705/208659ab9cef4fc4abcafb5661eaba66/artifacts', status='READY', status_message=None, tags={}, user_id='', version='2'>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mv=mlflow.register_model(model_uri=uri,name=\"production_model\")\n",
        "client.transition_model_version_stage(\n",
        "    name=\"production_model\",\n",
        "    version=mv.version,\n",
        "    stage=\"Production\",\n",
        "    model_id=\"\",\n",
        "    archive_existing_versions=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get_latest_model\n",
        "\n",
        "#get_production_model\n",
        "\n",
        "# if no production model -->  transition latest to production\n",
        "\n",
        "# if production model --> evaluate performance with latest to prod model\n",
        "        # latest better then latest to production\n",
        "            # production to staging\n",
        "\n",
        "        # else latest is bad\n",
        "            # get staging model\n",
        "                # -- staging found compare with staging if latest better replace staging and remove the previous  else archive latest\n",
        "                # else push latest to staging\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "run_id=runs[0].info.run_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Successfully registered model 'new_prod_model'.\n"
          ]
        },
        {
          "ename": "MlflowException",
          "evalue": "Unable to find a logged_model with artifact_path None under run 208659ab9cef4fc4abcafb5661eaba66",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mMlflowException\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mregister_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mruns:/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrun_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnew_prod_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlflow/lib/python3.12/site-packages/mlflow/tracking/_model_registry/fluent.py:129\u001b[39m, in \u001b[36mregister_model\u001b[39m\u001b[34m(model_uri, name, await_registration_for, tags, env_pack)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mregister_model\u001b[39m(\n\u001b[32m     62\u001b[39m     model_uri,\n\u001b[32m     63\u001b[39m     name,\n\u001b[32m   (...)\u001b[39m\u001b[32m     67\u001b[39m     env_pack: EnvPackType | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     68\u001b[39m ) -> ModelVersion:\n\u001b[32m     69\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a new model version in model registry for the model files specified by ``model_uri``.\u001b[39;00m\n\u001b[32m     70\u001b[39m \n\u001b[32m     71\u001b[39m \u001b[33;03m    Note that this method assumes the model registry backend URI is the same as that of the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    127\u001b[39m \u001b[33;03m        Version: 1\u001b[39;00m\n\u001b[32m    128\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_register_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m=\u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m        \u001b[49m\u001b[43menv_pack\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv_pack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlflow/lib/python3.12/site-packages/mlflow/tracking/_model_registry/fluent.py:180\u001b[39m, in \u001b[36m_register_model\u001b[39m\u001b[34m(model_uri, name, await_registration_for, tags, local_model_path, env_pack)\u001b[39m\n\u001b[32m    178\u001b[39m logged_models = _get_logged_models_from_run(run, artifact_path)\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logged_models:\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m    181\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnable to find a logged_model with artifact_path \u001b[39m\u001b[38;5;132;01m{\u001b[39;00martifact_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    182\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33munder run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    183\u001b[39m         error_code=ErrorCode.Name(NOT_FOUND),\n\u001b[32m    184\u001b[39m     )\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(logged_models) > \u001b[32m1\u001b[39m:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m run.outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[31mMlflowException\u001b[39m: Unable to find a logged_model with artifact_path None under run 208659ab9cef4fc4abcafb5661eaba66"
          ]
        }
      ],
      "source": [
        "mlflow.register_model(f\"runs:/{run_id}\",name=\"new_prod_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "class report: {'0': {'precision': 0.5966726618705036, 'recall': 0.6304038004750594, 'f1-score': 0.6130746130746131, 'support': 2105.0}, '1': {'precision': 0.5507210950867758, 'recall': 0.773695054945055, 'f1-score': 0.6434385263458517, 'support': 2912.0}, '2': {'precision': 0.39826839826839827, 'recall': 0.060170045781556575, 'f1-score': 0.10454545454545454, 'support': 1529.0}, 'accuracy': 0.5609532538955087, 'macro avg': {'precision': 0.5152207184085592, 'recall': 0.4880896337338903, 'f1-score': 0.4536861979886398, 'support': 6546.0}, 'weighted avg': {'precision': 0.5298882008986376, 'recall': 0.5609532538955087, 'f1-score': 0.5078009546656249, 'support': 6546.0}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/07 22:50:56 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "\u001b[31m2025/09/07 22:51:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run LSTM2 at: http://ec2-3-87-178-239.compute-1.amazonaws.com:5000/#/experiments/504809828903330705/runs/208659ab9cef4fc4abcafb5661eaba66\n",
            "🧪 View experiment at: http://ec2-3-87-178-239.compute-1.amazonaws.com:5000/#/experiments/504809828903330705\n"
          ]
        }
      ],
      "source": [
        "with mlflow.start_run():\n",
        "    mlflow.set_tag(\"mlflow.runName\",\"LSTM2\")\n",
        "    mlflow.set_tag(\"experiment_type\",\"algorithmic comparison\")\n",
        "    class_report,y_true_all,y_pred_all=evaluate_model(model,test_dataloader)\n",
        "    print(\"class report:\",class_report)\n",
        "    mlflow.log_param(\"Model\",\"LSTM\")\n",
        "    for metric in class_report:\n",
        "        if type(class_report[metric])==dict:\n",
        "            for key in class_report[metric]:\n",
        "                if key!=\"support\":\n",
        "                    mlflow.log_metric(f\"{metric}_{key}\",class_report[metric][key])\n",
        "        else:\n",
        "            mlflow.log_metric(metric,class_report[metric])\n",
        "    mlflow.pytorch.log_model(model,\"Lstm model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/07 22:46:02 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "\u001b[31m2025/09/07 22:46:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<mlflow.models.model.ModelInfo at 0x38a4c4830>"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlflow.pytorch.log_model(model,\"Lstm model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "wDwidxF_4pcP"
      },
      "outputs": [],
      "source": [
        "def store_best_model_lstm(model,test_dataloader):\n",
        "  with mlflow.start_run():\n",
        "    mlflow.set_tag(\"mlflow.runName\", \"LSTM\")\n",
        "    mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n",
        "    class_report,y_true_all,y_pred_all=evaluate_model(model,test_dataloader)\n",
        "    print(\"class report:\",class_report)\n",
        "    for metric in class_report:\n",
        "      mlflow.log_param(\"Model\",\"LSTM\")\n",
        "      for metric in class_report:\n",
        "        if type(class_report[metric])==dict:\n",
        "          for key in class_report[metric]:\n",
        "            if key!='support':\n",
        "              mlflow.log_metric(f\"{metric}_{key}\",class_report[metric][key])\n",
        "        else:\n",
        "          mlflow.log_metric(metric,class_report[metric])\n",
        "    mlflow.pytorch.log_model(model, \"Lstm model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O99gwnj9H_Ld",
        "outputId": "dee1a07d-b4cb-4a37-b1d5-1e938d2614ce"
      },
      "outputs": [
        {
          "ename": "MlflowException",
          "evalue": "API request to endpoint /api/2.0/mlflow/runs/create failed with error code 405 != 200. Response body: '<!doctype html>\n<html lang=en>\n<title>405 Method Not Allowed</title>\n<h1>Method Not Allowed</h1>\n<p>The method is not allowed for the requested URL.</p>\n'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mMlflowException\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mstore_best_model_lstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mstore_best_model_lstm\u001b[39m\u001b[34m(model, test_dataloader)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstore_best_model_lstm\u001b[39m(model,test_dataloader):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m      3\u001b[39m     mlflow.set_tag(\u001b[33m\"\u001b[39m\u001b[33mmlflow.runName\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mLSTM\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m     mlflow.set_tag(\u001b[33m\"\u001b[39m\u001b[33mexperiment_type\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33malgorithm_comparison\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlflow/lib/python3.12/site-packages/mlflow/tracking/fluent.py:474\u001b[39m, in \u001b[36mstart_run\u001b[39m\u001b[34m(run_id, experiment_id, run_name, nested, parent_run_id, tags, description, log_system_metrics)\u001b[39m\n\u001b[32m    470\u001b[39m         user_specified_tags[MLFLOW_RUN_NAME] = run_name\n\u001b[32m    472\u001b[39m     resolved_tags = context_registry.resolve_tags(user_specified_tags)\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m     active_run_obj = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexp_id_for_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresolved_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m log_system_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# If `log_system_metrics` is not specified, we will check environment variable.\u001b[39;00m\n\u001b[32m    482\u001b[39m     log_system_metrics = MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING.get()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlflow/lib/python3.12/site-packages/mlflow/tracking/client.py:435\u001b[39m, in \u001b[36mMlflowClient.create_run\u001b[39m\u001b[34m(self, experiment_id, start_time, tags, run_name)\u001b[39m\n\u001b[32m    381\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_run\u001b[39m(\n\u001b[32m    382\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    383\u001b[39m     experiment_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    386\u001b[39m     run_name: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    387\u001b[39m ) -> Run:\n\u001b[32m    388\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    389\u001b[39m \u001b[33;03m    Create a :py:class:`mlflow.entities.Run` object that can be associated with\u001b[39;00m\n\u001b[32m    390\u001b[39m \u001b[33;03m    metrics, parameters, artifacts, etc.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    433\u001b[39m \u001b[33;03m        status: RUNNING\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tracking_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlflow/lib/python3.12/site-packages/mlflow/tracking/_tracking_service/client.py:161\u001b[39m, in \u001b[36mTrackingServiceClient.create_run\u001b[39m\u001b[34m(self, experiment_id, start_time, tags, run_name)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;66;03m# Extract user from tags\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[38;5;66;03m# This logic is temporary; the user_id attribute of runs is deprecated and will be removed\u001b[39;00m\n\u001b[32m    158\u001b[39m \u001b[38;5;66;03m# in a later release.\u001b[39;00m\n\u001b[32m    159\u001b[39m user_id = tags.get(MLFLOW_USER, \u001b[33m\"\u001b[39m\u001b[33munknown\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mget_current_time_millis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRunTag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlflow/lib/python3.12/site-packages/mlflow/store/tracking/rest_store.py:272\u001b[39m, in \u001b[36mRestStore.create_run\u001b[39m\u001b[34m(self, experiment_id, user_id, start_time, tags, run_name)\u001b[39m\n\u001b[32m    262\u001b[39m tag_protos = [tag.to_proto() \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m tags]\n\u001b[32m    263\u001b[39m req_body = message_to_json(\n\u001b[32m    264\u001b[39m     CreateRun(\n\u001b[32m    265\u001b[39m         experiment_id=\u001b[38;5;28mstr\u001b[39m(experiment_id),\n\u001b[32m   (...)\u001b[39m\u001b[32m    270\u001b[39m     )\n\u001b[32m    271\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m response_proto = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCreateRun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Run.from_proto(response_proto.run)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlflow/lib/python3.12/site-packages/mlflow/store/tracking/rest_store.py:135\u001b[39m, in \u001b[36mRestStore._call_endpoint\u001b[39m\u001b[34m(self, api, json_body, endpoint, retry_timeout_seconds)\u001b[39m\n\u001b[32m    133\u001b[39m     endpoint, method = _METHOD_TO_INFO[api]\n\u001b[32m    134\u001b[39m response_proto = api.Response()\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_timeout_seconds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_timeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlflow/lib/python3.12/site-packages/mlflow/utils/rest_utils.py:590\u001b[39m, in \u001b[36mcall_endpoint\u001b[39m\u001b[34m(host_creds, endpoint, method, json_body, response_proto, extra_headers, retry_timeout_seconds)\u001b[39m\n\u001b[32m    587\u001b[39m     call_kwargs[\u001b[33m\"\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m\"\u001b[39m] = json_body\n\u001b[32m    588\u001b[39m     response = http_request(**call_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m590\u001b[39m response = \u001b[43mverify_rest_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m response_to_parse = response.text\n\u001b[32m    592\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlflow/lib/python3.12/site-packages/mlflow/utils/rest_utils.py:310\u001b[39m, in \u001b[36mverify_rest_response\u001b[39m\u001b[34m(response, endpoint)\u001b[39m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    306\u001b[39m         base_msg = (\n\u001b[32m    307\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAPI request to endpoint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    308\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfailed with error code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m != 200\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    309\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m    311\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Response body: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    312\u001b[39m             error_code=get_error_code(response.status_code),\n\u001b[32m    313\u001b[39m         )\n\u001b[32m    315\u001b[39m \u001b[38;5;66;03m# Skip validation for endpoints (e.g. DBFS file-download API) which may return a non-JSON\u001b[39;00m\n\u001b[32m    316\u001b[39m \u001b[38;5;66;03m# response\u001b[39;00m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m endpoint.startswith(_REST_API_PATH_PREFIX) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _can_parse_as_json_object(response.text):\n",
            "\u001b[31mMlflowException\u001b[39m: API request to endpoint /api/2.0/mlflow/runs/create failed with error code 405 != 200. Response body: '<!doctype html>\n<html lang=en>\n<title>405 Method Not Allowed</title>\n<h1>Method Not Allowed</h1>\n<p>The method is not allowed for the requested URL.</p>\n'"
          ]
        }
      ],
      "source": [
        "store_best_model_lstm(model,test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "jxAnTXRKIiNh"
      },
      "outputs": [],
      "source": [
        "# import boto3\n",
        "# from dotenv import load_dotenv\n",
        "# import os\n",
        "# load_dotenv()\n",
        "# aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID')\n",
        "# aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY')\n",
        "# s3_client=boto3.client('s3',\n",
        "#                        aws_access_key_id=aws_access_key_id,\n",
        "#                        aws_secret_access_key=aws_secret_access_key)\n",
        "# s3_client.upload_file(\n",
        "#     \"/Users/keertan.patro/Desktop/Practice/Yt_sentiment_analysis/Data/Clean/test_clean.csv\",\n",
        "#     \"yt-models-1\",\n",
        "#     \"test_clean.csv\"\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jKM1vNWZIwam"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[31m2025/09/09 00:09:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Downloading artifacts: 100%|██████████| 6/6 [00:07<00:00,  1.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions: [[-0.09084624 -0.07192243  0.03971712 -0.1197947   0.10352153  0.06640681\n",
            "  -0.03709073 -0.05424163 -0.03332851 -0.03506443]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import mlflow\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "model = NeuralNetwork()\n",
        "\n",
        "# Train your model (code omitted for brevity)\n",
        "\n",
        "model_info = mlflow.pytorch.log_model(model, name=\"model_test\")\n",
        "\n",
        "# Load and use the model\n",
        "loaded_model = mlflow.pyf.load_model(model_info.model_uri)\n",
        "\n",
        "# Make predictions\n",
        "sample_input = np.random.uniform(size=[1, 28, 28]).astype(np.float32)\n",
        "predictions = loaded_model.predict(sample_input)\n",
        "print(\"Predictions:\", predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading artifacts: 100%|██████████| 6/6 [00:05<00:00,  1.13it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear_relu_stack): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlflow.pytorch.load_model(model_info.model_uri)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_info.run_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'models:/m-065f8b88aa9947c68801a5d5ec726fcf'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_info.model_uri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_comment</th>\n",
              "      <th>category</th>\n",
              "      <th>new_clean_comment</th>\n",
              "      <th>processed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>found young modi guess which one</td>\n",
              "      <td>1</td>\n",
              "      <td>found young modi guess which one</td>\n",
              "      <td>found young modi guess one</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>holy shit heard the whole johnny gosch story e...</td>\n",
              "      <td>0</td>\n",
              "      <td>holy shit heard the whole johnny gosch story e...</td>\n",
              "      <td>holy shit heard whole johnny gosch story earli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>porra tava amando ler isso poderia pelo menos ...</td>\n",
              "      <td>0</td>\n",
              "      <td>porra tava amando ler isso poderia pelo menos ...</td>\n",
              "      <td>porra tava amando ler isso poderia pelo menos ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mmw will have something witty add this thread ...</td>\n",
              "      <td>1</td>\n",
              "      <td>mmw will have something witty add this thread ...</td>\n",
              "      <td>mmw something witty add thread diwali 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>have similar chart for call quality would lov...</td>\n",
              "      <td>0</td>\n",
              "      <td>have similar chart for call quality would love...</td>\n",
              "      <td>similar chart call quality would love see low ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       clean_comment  category  \\\n",
              "0                  found young modi guess which one          1   \n",
              "1  holy shit heard the whole johnny gosch story e...         0   \n",
              "2  porra tava amando ler isso poderia pelo menos ...         0   \n",
              "3  mmw will have something witty add this thread ...         1   \n",
              "4   have similar chart for call quality would lov...         0   \n",
              "\n",
              "                                   new_clean_comment  \\\n",
              "0                   found young modi guess which one   \n",
              "1  holy shit heard the whole johnny gosch story e...   \n",
              "2  porra tava amando ler isso poderia pelo menos ...   \n",
              "3  mmw will have something witty add this thread ...   \n",
              "4  have similar chart for call quality would love...   \n",
              "\n",
              "                                      processed_text  \n",
              "0                         found young modi guess one  \n",
              "1  holy shit heard whole johnny gosch story earli...  \n",
              "2  porra tava amando ler isso poderia pelo menos ...  \n",
              "3         mmw something witty add thread diwali 2016  \n",
              "4  similar chart call quality would love see low ...  "
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"/Users/keertan.patro/Desktop/Practice/Yt_sentiment_analysis/Data/Clean/train_clean.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.int64(10)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['processed_text'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  0, -1])"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['category'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_comment</th>\n",
              "      <th>category</th>\n",
              "      <th>new_clean_comment</th>\n",
              "      <th>processed_text</th>\n",
              "      <th>new_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>found young modi guess which one</td>\n",
              "      <td>1</td>\n",
              "      <td>found young modi guess which one</td>\n",
              "      <td>found young modi guess one</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>holy shit heard the whole johnny gosch story e...</td>\n",
              "      <td>0</td>\n",
              "      <td>holy shit heard the whole johnny gosch story e...</td>\n",
              "      <td>holy shit heard whole johnny gosch story earli...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>porra tava amando ler isso poderia pelo menos ...</td>\n",
              "      <td>0</td>\n",
              "      <td>porra tava amando ler isso poderia pelo menos ...</td>\n",
              "      <td>porra tava amando ler isso poderia pelo menos ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mmw will have something witty add this thread ...</td>\n",
              "      <td>1</td>\n",
              "      <td>mmw will have something witty add this thread ...</td>\n",
              "      <td>mmw something witty add thread diwali 2016</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>have similar chart for call quality would lov...</td>\n",
              "      <td>0</td>\n",
              "      <td>have similar chart for call quality would love...</td>\n",
              "      <td>similar chart call quality would love see low ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27573</th>\n",
              "      <td>nothing less was expected from bjp</td>\n",
              "      <td>-1</td>\n",
              "      <td>nothing less was expected from bjp</td>\n",
              "      <td>nothing less expected bjp</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27574</th>\n",
              "      <td>would just saying msm cant sensetionalize peo...</td>\n",
              "      <td>-1</td>\n",
              "      <td>would just saying msm cant sensetionalize peop...</td>\n",
              "      <td>would saying msm cant sensetionalize people ha...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27575</th>\n",
              "      <td>india will have counter strike team major atle...</td>\n",
              "      <td>1</td>\n",
              "      <td>india will have counter strike team major atle...</td>\n",
              "      <td>india counter strike team major atleast one three</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27576</th>\n",
              "      <td>well think just like family member the same li...</td>\n",
              "      <td>0</td>\n",
              "      <td>well think just like family member the same li...</td>\n",
              "      <td>well think like family member line line line l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27577</th>\n",
              "      <td>this very good stuff thank you for taking the ...</td>\n",
              "      <td>1</td>\n",
              "      <td>this very good stuff thank you for taking the ...</td>\n",
              "      <td>good stuff thank taking time post point raised...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27578 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           clean_comment  category  \\\n",
              "0                      found young modi guess which one          1   \n",
              "1      holy shit heard the whole johnny gosch story e...         0   \n",
              "2      porra tava amando ler isso poderia pelo menos ...         0   \n",
              "3      mmw will have something witty add this thread ...         1   \n",
              "4       have similar chart for call quality would lov...         0   \n",
              "...                                                  ...       ...   \n",
              "27573                nothing less was expected from bjp         -1   \n",
              "27574   would just saying msm cant sensetionalize peo...        -1   \n",
              "27575  india will have counter strike team major atle...         1   \n",
              "27576  well think just like family member the same li...         0   \n",
              "27577  this very good stuff thank you for taking the ...         1   \n",
              "\n",
              "                                       new_clean_comment  \\\n",
              "0                       found young modi guess which one   \n",
              "1      holy shit heard the whole johnny gosch story e...   \n",
              "2      porra tava amando ler isso poderia pelo menos ...   \n",
              "3      mmw will have something witty add this thread ...   \n",
              "4      have similar chart for call quality would love...   \n",
              "...                                                  ...   \n",
              "27573                 nothing less was expected from bjp   \n",
              "27574  would just saying msm cant sensetionalize peop...   \n",
              "27575  india will have counter strike team major atle...   \n",
              "27576  well think just like family member the same li...   \n",
              "27577  this very good stuff thank you for taking the ...   \n",
              "\n",
              "                                          processed_text  new_category  \n",
              "0                             found young modi guess one             1  \n",
              "1      holy shit heard whole johnny gosch story earli...             0  \n",
              "2      porra tava amando ler isso poderia pelo menos ...             0  \n",
              "3             mmw something witty add thread diwali 2016             1  \n",
              "4      similar chart call quality would love see low ...             0  \n",
              "...                                                  ...           ...  \n",
              "27573                          nothing less expected bjp             2  \n",
              "27574  would saying msm cant sensetionalize people ha...             2  \n",
              "27575  india counter strike team major atleast one three             1  \n",
              "27576  well think like family member line line line l...             0  \n",
              "27577  good stuff thank taking time post point raised...             1  \n",
              "\n",
              "[27578 rows x 5 columns]"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['new_category']=df['category'].map({1:1,0:0,-1:2})\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mlflow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
